{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "This is a guided walkthrough of how to resample your \"testing\" / input data to determine if it is likely that your data could be misclassified. A lot of the steps in this one will be very similar to the previous notebooks. The only real big difference is the resampling of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up and Running the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These first few steps will be drawn straight from the fire_svm notebook. If you want to know more about each step you can refer to that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Go to the right directory\n",
    "cd /Users/RichardP/research/icyfire/py\n",
    "\n",
    "#Import the packages\n",
    "import numpy as np\n",
    "\n",
    "import fire_data as dat\n",
    "import fire_svm as clf\n",
    "import fire_model as model\n",
    "import fire_cv as cv\n",
    "\n",
    "#Read out the data\n",
    "file_read = dat.file_read('Insert path to a sage file here')  \n",
    "data = dat.data_to_pytorch(file_read.data)\n",
    "name_labels = {}\n",
    "counter = 1\n",
    "for i in data.name_unique:\n",
    "    name_labels[i] = counter\n",
    "    counter += 1\n",
    "data.relabelling(name_labels)\n",
    "\n",
    "def multistep(actual):\n",
    "    mask = np.where(actual == 3)\n",
    "    acc = np.copy(actual)\n",
    "    acc[mask] = 2\n",
    "    return acc\n",
    "def deletion(data, actual):\n",
    "    mask = np.where(actual == 1)\n",
    "    data = np.delete(data, mask, axis = 0)\n",
    "    acc = np.copy(actual)\n",
    "    acc = np.delete(acc, mask)\n",
    "    return data, acc\n",
    "\n",
    "#Data separation and randomization\n",
    "label_carb = multistep(data.label)\n",
    "spectra_oxy, label_oxy = deletion(data.spectra, data.label)\n",
    "training_carb, testing_carb, train_carb, test_carb, = data.randomization(label_carb, data.spectra, 90)\n",
    "training_oxy, testing_oxy, train_oxy, test_oxy, = data.randomization(label_oxy, spectra_oxy, 90)\n",
    "\n",
    "#Generating our classifiers\n",
    "fire_carb = clf.svm_network(\n",
    "    training_carb['x'], training_carb['y'], \n",
    "    testing_carb['x'], testing_carb['y'], \n",
    "    c= 1, gamma = 0.01, kernel = 'rbf')\n",
    "fire_oxy = clf.svm_network(\n",
    "    training_oxy['x'], training_oxy['y'], \n",
    "    testing_oxy['x'], testing_oxy['y'], \n",
    "    c=2600, gamma = 0.0001, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "With our classifier set up we will start to resample the data. This involves using numpy.random.normal to take the actual flux value and the dflux value to generate a resampled flux value at each wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uncertainties = unc.data_uncertainty(file_read.data, test_carb)\n",
    "objects, fluxxing = uncertainties.gen_spec(\"Insert # of resamples for specific point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "Next we want to input our resampled data into the classifier.\n",
    "We will iterate over every source that is being tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our index we will plot 2 graphs here. The first graph is a bar chart indicating the number of counts for each type of prediction. The second graph is a histogram of the distribution of residuals (Resampled spectra - Actual spectra) for each prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at the differences in spectra for each prediction. We take the mean value of each wavelength and plot the error which is the standard deviation of the residual value from earlier before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we want to look at the distribution of where the error lies in comparison to other spectra. We plot a histogram distribution of the median residual values for each source (top graph) for each type of prediction. The bottom is a similar distribution, but instead it contains the counts of each spectra rather than for the whole source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = {}\n",
    "mask = {}\n",
    "for i in sorted(objects):\n",
    "    print('i')\n",
    "    predict[i], mask[i] = uncertainties.predicting(fire_carb.clf, objects, i)\n",
    "    uncertainties.plot_hist(predict, mask, fluxxing, i )\n",
    "    uncertainties.plot_resid(objects, fluxxing, mask, i )\n",
    "    uncertainties.plot_meds(fluxxing, mask, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all of our graphs for each source. Most sources will be fairly \"boring\" to look at, but some sources have very varied predictions which are of more importance. Some sources have fairly noisy spectra and so those are also some sources to take note of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
