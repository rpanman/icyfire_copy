{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "This is a guided walkthrough of how to optimize the support vector machine classifier. We'll be looking at using gridsearchCV to do this. This code usually takes a day to optimize but can be quicker with a smaller data set. You'll want to use this optimization for each type of classifier. When using different training data you'll want to optimize your classifier whether its each step of multistep classification or if you're doing a multi prediction classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up and Running the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These first few steps will be drawn straight from the fire_svm notebook. If you want to know more about each step you can refer to that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/RichardP/research/icyfire/py\n"
     ]
    }
   ],
   "source": [
    "cd /Users/RichardP/research/icyfire/py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import collections\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import fire_data as dat\n",
    "import fire_svm as clf\n",
    "import fire_model as model\n",
    "import fire_cv as cv\n",
    "import fire_org as org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dflux', 'flux', 'label', 'name', 'name_unique', 'spectra', 'wave']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_read = dat.file_read('/Users/RichardP/research/icyfire/data/sage5.fits')  \n",
    "data = dat.data_to_pytorch(file_read.data)\n",
    "name_labels = {}\n",
    "counter = 1\n",
    "for i in data.name_unique:\n",
    "    name_labels[i] = counter\n",
    "    counter += 1\n",
    "data.relabelling(name_labels)\n",
    "(sorted(data.__dict__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_carb = org.multistep(data.label)\n",
    "spectra_oxy, label_oxy = org.deletion(data.spectra, data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "For the actual optimization step we'll first want to create some arrays. We have our 2 parameters (we are only optimizing RBF kernel because RBF is generally superior) C and gamma. We also have an array for our loss. This is best used in the case when you're classifying more than 2 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.array([])\n",
    "gamma = np.array([])\n",
    "svm_loss= np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "For this next step we'll be optimizing our classifier. One thing thats very important is that you'll want to do this for every classifier. For my case with SAGE-Spec data I did two classifiers, one for carbon and the other for oxygen/RSG stars. The way it works is that you'll want to run the optimization 1000 different times. This is because you want to make sure the training and testing set you select are varied. If you optimize for one training set data then those parameters may not be true for other training sets. This is why if we run the optimization 1000 times we hope that the optimization will narrow down the parameters to eventually one set of numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1264.8552168552958, 1), (2682.6957952797247, 1), (1526.4179671752318, 1)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,1000):\n",
    "    training_carb, testing_carb, train_carb, test_carb, = data.randomization(label_carb, data.spectra, 90)\n",
    "    cross = cv.cross_validator(train_carb['x'],train_carb['y'], test_carb['x'], test_carb['y'])\n",
    "    c = np.append(c, cross.parameter1)\n",
    "    gamma = np.append(gamma, cross.parameter2)\n",
    "    svm_loss = np.append(svm_loss, cross.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "This next step there are many ways to approach it. Our optimizer outputted a distribution of the best parameters it chose for the given data set. However there are two parameters. The C parameter increases on a log scale (nature of the parameter) while the gamma scales by a factor of 10. You could just take the most common gamma parameter from the distribution and also take the median or mean of the C parameter. However the two parameters are somewhat linked. Therefore, what you should do is find the most common gamma parameter and look at only the C values that correspond to that gamma value. From there you select the most common one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma values: 0.0001, 0.0001, 0.0001\n",
      "Counts for 0.0001: 3\n",
      "C value: 1264.85521686\n",
      "Counts for 1264.85521686: 1\n"
     ]
    }
   ],
   "source": [
    "x = collections.Counter(gamma).most_common(3)\n",
    "print(\"Gamma values: \" + str(x[0][0]) + \", \" + str(x[1][0]) + \", \" + str(x[2][0]))\n",
    "print(\"Counts for Gamma: \" + str(x[0][1]) + \", \" + str(x[1][1]) + \", \" + str(x[2][1])\n",
    "mask = np.where(gamma == x[0][0])\n",
    "y = c[mask]\n",
    "z = collections.Counter(y).most_common(3)\n",
    "print(\"C value: \" + str(z[0][0]) + \", \" + str(z[1][0]) + \", \" + str(z[2][0]))\n",
    "print(\"Counts for C: \" + str(z[0][1]) + \", \" + str(z[1][1]) + \", \" + str(z[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have your optimized parameters that you can input into your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1.1em;\">\n",
    "One possible error is that since we trained with 90% of the data the parameters could slightly change once we input all 100% of the data. Again this is a possible error, but not one that I think will drastically change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
